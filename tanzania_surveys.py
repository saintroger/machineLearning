# -*- coding: utf-8 -*-
"""Tanzania Surveys.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gknUhReUeMr1AJuWnJbGBttXyp3bSddm
"""

import os
import pandas as pd
import numpy as np
!pip install pyreadstat
from google.colab import drive
drive.mount('/content/drive')

datapath = '/content/drive/MyDrive/Weather Risk/Data/Tanzania/'


#rename s2aq4 as acres
df_aga = pd.read_stata(datapath + '2008/SEC_2A.dta')
df_agb = pd.read_stata(datapath + '2008/SEC_2B.dta')
df_aga.info()
df_aga.isna().sum()
len(df_aga.hhid.unique())

#want to test what year has same hhid in it for aga1
df08 = pd.read_stata(datapath + '2008/SEC_2A.dta')
df10 = pd.read_spss(datapath + '2010/AG_SEC2A.SAV')
df12 = pd.read_csv(datapath + '2012/AG_SEC_2A.csv')
df14 = pd.read_csv(datapath + '2014/ag_sec_2a.csv')
df19 = pd.read_csv(datapath + '2019/ag_sec_02.csv')
hh08 = pd.read_stata(datapath + '2008/SEC_A.dta')
hh10 = pd.read_spss(datapath + '2010/HH_SEC_B.SAV')
hh19 = pd.read_csv(datapath + '2019/hh_sec_b.csv')
ag17 = pd.read_stata(datapath + '2017/S23_1.dta')

"""KEY
 * hh(year): HH_sec_a which is household location info
 * agri(year)_long: this is Ag_SEC_2A <- farm land info in long rainy season
 * agri(year)_short: this ag_sec_2b <- farm land info in short rainy season
 * prod(year)_long: ag_sec_4A <- production info in long rainy season
 * prod(year)_short: ag_sec_4b <- production info short rainy season
 * agri(year): merged long and short
 * agri_area: merged agri(year) with hh(year)
 * prod(year): merged long and short
 * survey(year): agri_area with prod(year)

NOTES
 * might not need plotID
 * EAs: In NPS 2008/2009, enumeration areas (EAs) were selected and then households within those EAs were selected for the sample. For the third round, households from the second round were grouped into clusters. These third round clusters are very similar to the EAs from the second round in that they both consist of primarily the same households. However, each cluster also included both distance and local tracking cases from the second round that reside nearby but not in the same exact EA as the other households in that cluster. Efforts were made in the design of the clusters to be able to maintain the timing of the previous rounds survey.
 * GIS data: Tanzania NBS has only posted up to level 3(wards) for GIS data from 2002-2012.
 * individual households don't need to be consistent throughout years
 * PlotID is not needed
 * ward name is confidential and only avaliable in 2012 survey (hh_a03_2)
 * Issue with survey 2008 wards,not all wards are ccovered in GIS data (14,  3, 17, 38,  9, 10, 29,  24,  1,  2,  6,  4,  7, 15, 27,  8, 34, 19, 18,  5, 20, 16, 37, 28, 25, 30, 26) only (11, 12, 13, 21, 22, 23, 31)

#2008
"""

#Starting from the beginning for 2008 with proper columns needed

hh08 = pd.read_stata(datapath + '2008/SEC_A_T.dta')
agri08_long = pd.read_stata(datapath + '2008/SEC_2A.dta')
agri08_short = pd.read_stata(datapath + '2008/SEC_2B.dta')
prod08_long = pd.read_stata(datapath+'2008/SEC_4A.dta')
prod08_short =pd.read_stata(datapath+'2008/SEC_4B.dta')

hh08

#getting information on area
hh08.columns
hh08=hh08[['hhid', 'clusterid','region', 'district', 'ward', 'ea' ]]
hh08.info()

#getting information on farming area and plot size
agri08_short.columns=agri08_short.columns.str.replace('s2bq9', 's2aq4')
agri08=pd.concat([agri08_long,agri08_short])
agri08.info()

#Merging area info with land size info
agri08_area=agri08.merge(hh08, on='hhid')
agri08_area.info()

#getting info on farm production and season
prod08_long['rainy season'] = 'long'
prod08_short['rainy season'] = 'short'
prod08_short.columns=prod08_short.columns.str.replace('b', 'a')
prod08=pd.concat([prod08_long, prod08_short])
prod08.columns
prod08=prod08[['hhid', 'plotnum', 'zaocode', 'rainy season', 's4aq3', 's4aq4','s4aq15']]
prod08.info()

#merging production and area info for final survey info
#total harvest is the amount of harvest of all crops on plot.
#maize per acre = (total harvest * area fract) / (est area or gps area)
#*** must change area fraction into float
survey08=prod08.merge(agri08_area, on=['hhid', 'plotnum'])
survey08.rename(columns ={'s4aq3': 'single crop',
                          's4aq15': 'total harvest', 's2aq4': 'est area',
                          'area': 'gps area', 'hhid': 'y1_hhid', 'plotnum': 'y1plotnum'}, inplace = True)
survey08=survey08[['y1_hhid','clusterid','region','district','ward', 'ea',
                   'y1plotnum','est area', 'gps area', 'zaocode','single crop',
                   's4aq4', 'total harvest',  'rainy season']]
survey08=survey08[survey08['zaocode'] ==	'Maize']

#All na values of single crop has no info on harvest and area fract and is dropped
survey08[survey08['single crop'].isnull()].info()

#ONLY RUN ONCE OR WILL RESET ALL TO
#changing area fraction into float
survey08.dropna(subset=['single crop'], inplace=True)
#should drop observations with no plot fraction
conditions = [
    (survey08['single crop'] == 'YES'), (survey08['s4aq4'] == 'HALF'),
    (survey08['s4aq4'] == 'QUARTER'),
    (survey08['s4aq4'] == 'THREE-QUARTER')
    ]

# create a list of the values we want to assign for each condition
values = [1, 0.5, 0.25, 0.75]

# create a new column and use np.select to assign values to it using our lists as arguments
survey08['area fract'] = np.select(conditions, values)

#gettinf rid of observations with no plot fraction

 #or
survey08.drop(columns=['s4aq4'], inplace=True)

#only two observations dont have total harvest data and are dropped
survey08[survey08['total harvest'].isnull()]
survey08.dropna(subset=['total harvest'], inplace= True)

#create year variable
survey08['year'] = 2008

#only gps area has missing variables, currently 2262 individual households.
survey08.info()

#Some rgions are all caps
survey08.region=survey08.region.str.capitalize()

survey08

hh12_a = pd.read_csv(datapath + '2012/HH_SEC_A.csv')



"""# 2010"""

agri10_long = pd.read_spss(datapath + '2010/AG_SEC2A.SAV')
agri10_short = pd.read_spss(datapath + '2010/AG_SEC2B.SAV')
hh10_a = pd.read_spss(datapath + '2010/HH_SEC_A.SAV')
hh10_b = pd.read_spss(datapath + '2010/HH_SEC_B.SAV')
prod10_long = pd.read_spss(datapath + '2010/AG_SEC4A.SAV')
prod10_short =pd.read_spss(datapath + '2010/AG_SEC4B.SAV')

#contains location info but no 2008 hhid's
hh10_a.columns
hh10_a=hh10_a[['y2_hhid', 'clusterid', 'region', 'district', 'ward', 'ea', 'hh_a05']]

#doesn't include any location information but has 2008 hhid's
hh10_b.columns
hh10_b=hh10_b[['y2_hhid', 'hhid_2008']]

#merging both household location datasets
hh10=hh10_a.merge(hh10_b, on='y2_hhid')[['y2_hhid', 'hhid_2008','clusterid', 'region', 'district', 'ward', 'ea', 'hh_a05']]
hh10 = hh10.drop_duplicates()
hh10.info()

#working with land use data
agri10_short.columns=agri10_short.columns.str.replace('ag2b_15', 'ag2a_04')
agri10_short.columns=agri10_short.columns.str.replace('ag2b_20', 'ag2a_09')
agri10_short.columns=agri10_short.columns.str.replace('ag2b_15', 'ag2a_09')

#merging both long and short
agri10=pd.concat([agri10_long,agri10_short])
agri10.columns
agri10=agri10[['y2_hhid', 'plotnum', 'y1plotnum', 'ag2a_04', 'ag2a_09']]
agri10.info()

#merging household with land use data
agri10_area=agri10.merge(hh10, on='y2_hhid', how='left')
agri10_area=agri10_area.drop_duplicates()
agri10_area.info()

#working with production data
prod10_short.columns=prod10_short.columns.str.replace('b', 'a')
prod10_short['rainy season'] = 'short'
prod10_long['rainy season'] = 'long'
#merging data
prod10=pd.concat([prod10_long, prod10_short])
prod10=prod10[['y2_hhid', 'plotnum', 'zaocode', 'rainy season', 'ag4a_01', 'ag4a_02','ag4a_15']]
prod10.info()

survey10 = prod10.merge(agri10_area, on = ['y2_hhid', 'plotnum'])[
    ['y2_hhid','hhid_2008', 'clusterid', 'region', 'district', 'ward', 'ea',
     'hh_a05', 'plotnum', 'y1plotnum','ag2a_04', 'ag2a_09', 'zaocode',
     'ag4a_01', 'ag4a_02','ag4a_15','rainy season']
     ]
survey10['year'] = 2010
survey10=survey10[survey10['zaocode'] ==	'Maize']
survey10.info()

survey10.rename(columns={'hh_a05':'street', 'ag2a_04': 'est area',
                       'ag2a_09': 'gps area', 'ag4a_01': 'single crop',
                       'hhid_2008':'y1_hhid','ag4a_15': 'total harvest',
                       'plotnum': 'y2plotnum'},inplace= True)
survey10.info()

#ONLY RUN ONCE OR WILL RESET ALL TO
#changing area fraction into float

#should drop observations with no plot fraction
conditions = [
    (survey10['single crop'] == 'YES'), (survey10['ag4a_02'] == '1/2'),
    (survey10['ag4a_02'] == '1/4'),
    (survey10['ag4a_02'] == '3/4')
    ]

# create a list of the values we want to assign for each condition
values = [1, 0.5, 0.25, 0.75]

# create a new column and use np.select to assign values to it using our lists as arguments
survey10['area fract'] = np.select(conditions, values)

#gettinf rid of observations with no plot fraction

 #or
survey10.drop(columns=['ag4a_02'], inplace=True)

survey10.info()
survey10.columns

#wave2 only has region id but not name
regionname=hh12_a[['hh_a01_1', 'hh_a01_2']]
regionname.rename(columns={'hh_a01_1': 'region'}, inplace = True)

survey10=survey10.merge(regionname, on='region')
survey10=survey10.drop_duplicates()

survey10.drop(columns=['region'], inplace=True)
survey10.rename(columns={'hh_a01_2': 'region'}, inplace = True)
survey10

#Some rgions are all caps
survey10.region=survey10.region.str.capitalize()
survey10=survey10[['y2_hhid', 'y1_hhid', 'clusterid','region', 'district',
                   'ward', 'ea', 'street','y2plotnum', 'y1plotnum', 'est area',
                   'gps area','zaocode','single crop', 'total harvest',
                   'rainy season','year', 'area fract']]

"""#2012"""

hh12_a = pd.read_csv(datapath + '2012/HH_SEC_A.csv')
hh12_b = pd.read_csv(datapath + '2012/HH_SEC_B.csv')
agri12_long = pd.read_csv(datapath + '2012/AG_SEC_2A.csv')
agri12_short = pd.read_csv(datapath + '2012/AG_SEC_2B.csv')
prod12_long = pd.read_csv(datapath+'2012/AG_SEC_4A.csv')
prod12_short =pd.read_csv(datapath+'2012/AG_SEC_4B.csv')

hh12_b=hh12_b[['y3_hhid', 'y2_hhid']]
hh12_b['y2_hhid'] = hh12_b['y2_hhid'].fillna(-1)
hh12_b['y2_hhid'] = hh12_b['y2_hhid'].astype(int)
hh12_b['y2_hhid'] = hh12_b['y2_hhid'].astype(str)
hh12_b['y2_hhid'] = hh12_b['y2_hhid'].replace('-1', np.nan, regex=True)
hh12_b['y2_hhid'] = hh12_b['y2_hhid'].astype(object)
hh12_b.info()

hh12_a=hh12_a[['y3_hhid', 'hh_a06', 'hh_a13',
       'clusterid', 'strataid', 'hh_a01_2', 'hh_a02_1', 'hh_a03_1', 'hh_a04_1']]
hh12_a.info()

hh12=hh12_a.merge(hh12_b, on='y3_hhid')
hh12=hh12.drop_duplicates()
hh12.info()

#working with land use data
agri12_short.columns=agri12_short.columns.str.replace('ag2b_15', 'ag2a_04')
agri12_short.columns=agri12_short.columns.str.replace('ag2b_20', 'ag2a_09')
agri12_short.columns=agri12_short.columns.str.replace('ag2b_05', 'ag2a_05')

#merging both long and short
agri12=pd.concat([agri12_long,agri12_short])
agri12.columns
agri12=agri12[['y3_hhid', 'plotnum', 'ag2a_05', 'ag2a_04', 'ag2a_09']]
agri12=agri12.drop_duplicates()
agri12.info()

#merging household with land use data
agri12_area=agri12.merge(hh12, on='y3_hhid')
agri12_area=agri12_area.drop_duplicates()
agri12_area.info()
agri12_area.columns

#working with production data
prod12_short.columns=prod12_short.columns.str.replace('b', 'a')
prod12_short['rainy season'] = 'short'
prod12_long['rainy season'] = 'long'
#merging data
prod12=pd.concat([prod12_long, prod12_short])
prod12=prod12[['y3_hhid', 'plotnum', 'zaocode', 'rainy season', 'ag4a_01', 'ag4a_02','ag4a_28']]
prod12.info()

survey12=prod12.merge(agri12_area, on = ['y3_hhid', 'plotnum'])
survey12=survey12.drop_duplicates()
survey12=survey12[['y3_hhid', 'y2_hhid', 'clusterid', 'hh_a01_2', 'hh_a02_1',
       'hh_a03_1', 'hh_a04_1', 'plotnum', 'ag2a_05','ag2a_04', 'ag2a_09',
       'zaocode','ag4a_01', 'ag4a_02','ag4a_28','rainy season']]
survey12['year'] = 2012
survey12=survey12[survey12['zaocode'] ==	11]

survey12

survey12.rename(columns={'hh_a01_2': 'region', 'hh_a02_1': 'district','hh_a03_1': 'ward',
                'hh_a04_1': 'ea', 'ag2a_04': 'est area',
                       'ag2a_09': 'gps area', 'ag4a_01': 'single crop',
                        'ag4a_28': 'total harvest', 'ag2a_05': 'y2plotnum', 'plotnum':'y3plotnum' },inplace= True)
survey12.info()
survey12

#ONLY RUN ONCE OR WILL RESET ALL TO
#changing area fraction into float

#should drop observations with no plot fraction
conditions = [
    (survey12['single crop'] == 1 ), (survey12['ag4a_02'] == 2),
    (survey12['ag4a_02'] == 1),
    (survey12['ag4a_02'] == 3)
    ]

# create a list of the values we want to assign for each condition
values = [1, 0.5, 0.25, 0.75]

# create a new column and use np.select to assign values to it using our lists as arguments
survey12['area fract'] = np.select(conditions, values)

#formatting to match other 2 surveys
survey12['single crop']=survey12['single crop'].apply(lambda x: 'YES' if x == 1 else 'NO' )
survey12['zaocode']=survey12['zaocode'].apply(lambda x: 'Maize' if x == 11 else 'umm' )


 #or
survey12.drop(columns=['ag4a_02'], inplace=True)

survey12.columns
survey12=survey12[['y3_hhid', 'y2_hhid', 'clusterid', 'region', 'district', 'ward', 'ea',
       'y3plotnum', 'y2plotnum', 'est area', 'gps area', 'zaocode',
       'single crop','area fract', 'total harvest', 'rainy season', 'year']]

#Some rgions are all caps
survey12.region=survey12.region.str.capitalize()

"""#2014"""

agri14_long = pd.read_csv(datapath+'2014/ag_sec_2a.csv')
agri14_short = pd.read_csv(datapath+'2014/ag_sec_2b.csv')
hh14_a = pd.read_csv(datapath+'2014/hh_sec_a.csv')
prod14_long = pd.read_csv(datapath+'2014/ag_sec_4a.csv')
prod14_short =pd.read_csv(datapath+'2014/ag_sec_4b.csv')

hh14_a.columns
hh14=hh14_a[['y4_hhid', 'domain',
       'clusterid','hh_a01_2', 'hh_a02_1', 'hh_a03_1']]
hh14.rename(columns={'hh_a01_2':'region', 'hh_a02_1':'district', 'hh_a03_1':'ward'}, inplace=True)
hh14.region=hh14.region.str.capitalize()
hh14



agri14_short.columns

agri14_long.columns

agri14_short.columns=agri14_short.columns.str.replace('ag2b_15', 'ag2a_04')
agri14_short.columns=agri14_short.columns.str.replace('ag2b_20', 'ag2a_09')

agri14=pd.concat([agri14_long,agri14_short])
agri14.columns
agri14=agri14[['y4_hhid','plotnum','ag2a_04', 'ag2a_09']]
agri14

agri14_area=agri14.merge(hh14, on='y4_hhid').drop_duplicates()
agri14_area.info()

prod14_short.columns=prod14_short.columns.str.replace('b', 'a')
prod14_short['rainy season'] = 'short'
prod14_long['rainy season'] = 'long'
#merging data
prod14=pd.concat([prod14_long, prod14_short])
prod14=prod14[['y4_hhid', 'plotnum', 'zaocode', 'rainy season', 'ag4a_01', 'ag4a_02','ag4a_28']]
prod14.info()

survey14=prod14.merge(agri14_area, on = ['y4_hhid', 'plotnum']).drop_duplicates()
survey14
survey14=survey14[['y4_hhid', 'clusterid','region', 'district', 'ward',
                   'plotnum','ag2a_04', 'ag2a_09', 'zaocode',
                   'ag4a_01', 'ag4a_02','ag4a_28','rainy season']]
survey14['year'] = 2014
survey14=survey14[survey14['zaocode'] ==	11]

survey14

survey14.rename(columns={ 'ag2a_04': 'est area', 'ag2a_09': 'gps area',
                         'ag4a_01': 'single crop','ag4a_28': 'total harvest'},inplace= True)

survey14

#ONLY RUN ONCE OR WILL RESET ALL TO
#changing area fraction into float

#should drop observations with no plot fraction
conditions = [
    (survey14['single crop'] == 1 ), (survey14['ag4a_02'] == 2),
    (survey14['ag4a_02'] == 1),
    (survey14['ag4a_02'] == 3)
    ]

# create a list of the values we want to assign for each condition
values = [1, 0.5, 0.25, 0.75]

# create a new column and use np.select to assign values to it using our lists as arguments
survey14['area fract'] = np.select(conditions, values)

#formatting to match other 2 surveys
survey14['single crop']=survey14['single crop'].apply(lambda x: 'YES' if x == 1 else 'NO' )
survey14['zaocode']=survey14['zaocode'].apply(lambda x: 'Maize' if x == 11 else 'umm' )


 #or
survey14.drop(columns=['ag4a_02'], inplace=True)

survey14=survey14[['y4_hhid','clusterid', 'region', 'district', 'ward', 'plotnum',
          'est area', 'gps area', 'zaocode','single crop','area fract',
          'total harvest', 'rainy season', 'year']]
survey14

"""#2019

If an entire household had moved from the original residence, teams were required to complete a
“T-1” form designed to capture relevant information from key informants on the whereabouts of
the household. The T-1 form contains information that would enable tracking of household to its
new location. If a member or members of the household have moved from the original household,
a “T-2” form was completed by the teams. Similar to the T-1, a T-2 form contains information on
the location of the member(s) who have moved from the household. Once the tracking targets had
been located, teams were required to interview the household as consistent with the eligibility
requirements.

The variable loc_info distinguishes whether or not a household was in the same physical location as the previous
round, NPSY4. For split-off households, this variable will be blank. For original households, if the answer is
“NO”, then new household location information will be provided in the variables with the prefix “hh_a”, (i.e.
hh_a01_1, hh_a02_1, etc). If the answer is “YES”, then the household has confirmed they are in the same
location and the only household location information available will be in the variables with the prefix “t0_”
(t0_region, t0_district, etc.), and no new location information will be provided.

* 2019 does have all location information, trying to figure out how to move t_0s and hh_as into one column
"""

import sys
import numpy
numpy.set_printoptions(threshold=sys.maxsize)

agri19 = pd.read_csv(datapath+'2019/ag_sec_02.csv')
hh19_a = pd.read_csv(datapath+'2019/hh_sec_a.csv')

prod19_long = pd.read_csv(datapath+'2019/ag_sec_4a.csv')
prod19_short =pd.read_csv(datapath+'2019/ag_sec_4b.csv')

hh19_a.columns

#same vs moved
#t0_region = hh_a01_1
#t0_district = hh_a02_1
#t0_ward_code = hh_a03_1
#t0_ea_codee = hh_a04_1

hmm=hh19_a[['y4_hhid', 'sdd_hhid', 'domain', 'clusterid','loc_info','hh_a01_1',
             't0_region', 'hh_a02_1', 't0_district', 'hh_a03_1', 't0_ward_code', 't0_ea_codee', 'hh_a04_1']]
hmm[hmm['loc_info']==1]
hmm.rename(columns={'hh_a01_1': 'region', 'hh_a02_1': 'district', 'hh_a03_1':'ward', 'hh_a04_1':'ea'}, inplace=True)
hmm

hmm[hmm['loc_info']==1]

hh19=hh19_a[['y4_hhid', 'sdd_hhid', 'domain', 'clusterid','hh_a01_1', 'hh_a02_1',
             'hh_a03_1']]
hh19.rename(columns={'hh_a01_1':'region_C', 'hh_a02_1':'district', 'hh_a03_1':'ward'}, inplace=True)

#gotta reorder 2019 y4_hhid code to match 2014 to find NaN area info(region,district,ward)
#replacing the first element '0' in y4_hhid 2019 with 1 to formulate with 2014 year
hh19.y4_hhid=hh19['y4_hhid'].str.replace('0', '1', 1)

hh19

agri19.columns
agri19=agri19[['sdd_hhid', 'plotnum','ag2a_05', 'ag2a_04',
               'ag2a_09' ]]

agri19_area=agri19.merge(hh19, on='sdd_hhid').drop_duplicates()
agri19_area

prod19_short.columns=prod19_short.columns.str.replace('b', 'a')
prod19_short['rainy season'] = 'short'
prod19_long['rainy season'] = 'long'
#merging data
prod19=pd.concat([prod19_long, prod19_short])
prod19=prod19[['sdd_hhid', 'plotnum', 'cropid', 'rainy season', 'ag4a_01', 'ag4a_02','ag4a_28']]
prod19

survey19=prod19.merge(agri19_area, on = ['sdd_hhid', 'plotnum']).drop_duplicates()
survey19
survey19=survey19[['sdd_hhid','y4_hhid', 'clusterid','region_C', 'district', 'ward',
                   'plotnum','ag2a_05', 'ag2a_04', 'ag2a_09', 'cropid',
                   'ag4a_01', 'ag4a_02','ag4a_28','rainy season']]
survey19['year'] = 2019
survey19=survey19[survey19['cropid'] ==	11]

survey19

survey19.rename(columns={ 'ag2a_04': 'est area', 'ag2a_09': 'gps area',
                         'ag4a_01': 'single crop','ag4a_28': 'total harvest'},inplace= True)

survey19

#ONLY RUN ONCE OR WILL RESET ALL TO
#changing area fraction into float

#should drop observations with no plot fraction
conditions = [
    (survey19['single crop'] == 1 ), (survey19['ag4a_02'] == 2),
    (survey19['ag4a_02'] == 1),
    (survey19['ag4a_02'] == 3)
    ]

# create a list of the values we want to assign for each condition
values = [1, 0.5, 0.25, 0.75]

# create a new column and use np.select to assign values to it using our lists as arguments
survey19['area fract'] = np.select(conditions, values)

#formatting to match other 2 surveys
survey19['single crop']=survey19['single crop'].apply(lambda x: 'YES' if x == 1 else 'NO' )
survey19['zaocode']=survey19['cropid'].apply(lambda x: 'Maize' if x == 11 else 'umm' )


 #or
survey19.drop(columns=['ag4a_02'], inplace=True)

survey19=survey19[['y4_hhid','clusterid', 'region_C', 'district', 'ward', 'plotnum','ag2a_05',
          'est area', 'gps area', 'zaocode','single crop','area fract',
          'total harvest', 'rainy season', 'year']]
survey19.info()

"""### Issues
* Nans makes up a large portion of data
* Majority of households dont have location information
* survey 14 can only account for 49/507 missing regions
"""

missdf=survey14[['y4_hhid', 'plotnum', 'region', 'district', 'ward']]

survey19.isna().sum()

miss=survey19[survey19['region_C'].isna()]
len(miss)

survey14[survey14['y4_hhid']=='1003-001']

len(miss.merge(missdf, on='y4_hhid'))

#gotta reorder 2019 y4_hhid code to match 2014 to find NaN area info(region,district,ward)
#replacing the first element '0' in y4_hhid 2019 with 1 to formulate with 2014 year
survey19

#2019 data has many nan values for region, district and ward. Attempting to fill in blanks using 2014 data
#its likely that the households changesd between survey periods (3 years), and plotnum isn't a good refence
#to compare between moved or not moved. Should read basic info report to double check.
#507 missing region, 508 missing district, 529 missing ward

"""# Merging 2008-2013

Testing merg without plotID
"""



survey08.head()

survey10.head()

index= survey10[['y1_hhid', 'y2_hhid']]

wave1= survey08[['y1_hhid', 'clusterid', 'region', 'district', 'ward', 'ea','year',
       'est area', 'gps area', 'zaocode','single crop', 'total harvest',
       'rainy season',  'area fract']]
wave1

wave2 = survey10[['y1_hhid', 'clusterid', 'region', 'district', 'ward', 'ea','year',
       'est area', 'gps area', 'zaocode','single crop', 'total harvest',
       'rainy season',  'area fract']]
wave2

wave3=survey12.merge(index, on='y2_hhid').drop_duplicates()
wave3=wave3[['y1_hhid', 'clusterid', 'region', 'district', 'ward', 'ea','year',
       'est area', 'gps area', 'zaocode','single crop', 'total harvest',
       'rainy season',  'area fract']]
wave3

wavefull=pd.concat([wave1, wave2, wave3])
wavefull.info()

wavefull

wavefull.to_csv('/content/drive/MyDrive/tz0812.csv')

"""# Merge 2014-2019"""

survey14.head()
survey14['plotnum'].unique()

wave5=survey19.rename(columns={'region_C':'Region_Cod'})
wave5=pd.merge(regioncodes,wave5, on=['Region_Cod'], how='right').drop_duplicates()
wave5.drop(columns=['Region_Cod'])
wave5.info()

#Reformatting plotnum
wave5['plotnum'].unique()
wave5.plotnum=wave5.plotnum.astype(str)
wave5.plotnum=wave5.plotnum.str.replace('', 'M', 1)

wave5.drop(columns=['Region_Cod', 'ag2a_05'], inplace=True)

wave5

survey14

wave_full2=pd.concat([survey14, wave5])

"""# GEO data
 * 30 regions
 * 10 districts
 * 127 wards
"""

geo=pd.read_csv(datapath +'/TZN.csv')

#Renaming variables for surveys
geo.rename(columns={'Ward_Code':'ward', 'District_C': 'district', 'Region_Nam':'region'}, inplace=True)
geo.head()

geo.region.unique()

geo.region.value_counts()

geo.district.unique()

geo.district.value_counts()

len(geo.ward.unique())

geo

# region, district, ward names and codes
regioncodes=geo[['region', 'Region_Cod']]
districtcodes = geo[['district', 'District_N']]
wardcodes = geo[['ward', 'Ward_Name']]
geospace=geo[['region', 'Region_Cod','district', 'District_N', 'ward', 'Ward_Name']]

wavefull.info()

wave_full2.info()

#This is 2008-2013 households with geospace and names
wavefull_geo=pd.merge(wavefull, geospace, on=['region','district', 'ward'], how='left').drop_duplicates()
wavefull_geo

"""### losing 60 observations why?"""

#losing 60 observations, Why?
len(wavefull) - len(wavefull_geo)

#28 from 2008 survey
len(wavefull[wavefull['year']==2008]) - len(wavefull_geo[wavefull_geo['year']==2008])
wavefull[wavefull['year']==2008]

#10 fr0m 2010
len(wavefull[wavefull['year']==2010]) - len(wavefull_geo[wavefull_geo['year']==2010])

#22 from 2012
len(wavefull[wavefull['year']==2012]) - len(wavefull_geo[wavefull_geo['year']==2012])

wavefull.merge(geospace, on =['region','district', 'ward']).drop_duplicates()

"""###survey 2008
 * 26/30 regions (1-21) excluding 7
 * 8/10 districts (1-8)
 * only 7/34 wards are in geo(11, 12, 13, 21, 22, 23, 31). 7/127
"""

survey08.head()

#Some regions aare Capital some lower case make these consistent.
survey08.region=survey08.region.str.capitalize()
len(survey08.region.unique())
survey08['region'].value_counts()

len(survey08['district'].unique())
survey08.district.value_counts()

len(survey08['ward'].unique())
#survey08.ward.value_counts()

wards08 = survey08.merge(wardcodes, on='ward').drop_duplicates()
wards08=wards08.ward.unique()
wards08

#These are the amount of locations shown by geo data that is referenced by 2008.
#Therefore only 19.98% of Maize data can be mapped on the ward level.
geo[geo['ward'].isin(wards08)]
geo11=geo[geo['ward']==11]
geo11['Ward_Name'].unique()

survey08

wave1=survey08.merge(geospace, on=['district', 'ward', 'region']).drop_duplicates()
wave1

survey08.region.value_counts()

wave1.region.value_counts()

survey08.district.value_counts()

wave1.district.value_counts()

survey08.ward.value_counts()

wave1.ward.value_counts()

len(geo[geo['ward']==21])





"""**bold text**##Needed Columns

#production
Survey Year,	Survey Section,	Seaso,n	Crop Code,	Crop Name,Quantity,	Conversion	Plot, Section	Plot, Crop Name,	Plot Crop Code,	Area Planted,	Percent Crop.

In the survey, maize production is reported at
96 the plot level in kilograms along with the plot size in acres and the share of the plot used for maize. The
97 total production figure is multiplied by the maize share of the plot and divided by the plot size to obtain
98 maize produced per acre.

#full survey
district_name,	codes, hhid	total_production,	total_area,	Year,	season,	per_hectare,	HHID,	region,	h1aq1,	h1aq2b,	h1aq3b,	Parish,	regional_avg

**when dealing with how the land was used: should I look

##Questions
#How should I proceed with the following:
How was land used?: filter for cultivated

What crop was grow?: Filter for maize/mahindi

Was the plot measured?: Filter for yes
"""